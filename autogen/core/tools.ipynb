{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-ext in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (0.4.9.2)\n",
      "Requirement already satisfied: docker in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (7.1.0)\n",
      "Requirement already satisfied: asyncio_atexit in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: autogen-core==0.4.9.2 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from autogen-ext) (0.4.9.2)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from autogen-core==0.4.9.2->autogen-ext) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from autogen-core==0.4.9.2->autogen-ext) (1.31.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from autogen-core==0.4.9.2->autogen-ext) (11.1.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from autogen-core==0.4.9.2->autogen-ext) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from autogen-core==0.4.9.2->autogen-ext) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from autogen-core==0.4.9.2->autogen-ext) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from docker) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from docker) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from requests>=2.26.0->docker) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from requests>=2.26.0->docker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from requests>=2.26.0->docker) (2025.1.31)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-ext) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-ext) (8.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.9.2->autogen-ext) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.9.2->autogen-ext) (2.27.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-ext) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/kevinlights/app/miniforge3/envs/open_manus/lib/python3.12/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-ext) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install autogen-ext docker asyncio_atexit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\n",
    "from autogen_ext.tools.code_execution import PythonCodeExecutionTool\n",
    "\n",
    "# Create the tool.\n",
    "code_executor = DockerCommandLineCodeExecutor(image=\"python:3-slim\")\n",
    "await code_executor.start()\n",
    "code_execution_tool = PythonCodeExecutionTool(code_executor)\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Use the tool directly without an agent.\n",
    "code = \"import sys\\nprint('Hello, world!')\\nsys.exit(0)\"\n",
    "result = await code_execution_tool.run_json({\"code\": code}, cancellation_token)\n",
    "print(code_execution_tool.return_value_as_string(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = await code_execution_tool.run_json({\"code\": code}, cancellation_token)\n",
    "print(code_execution_tool.return_value_as_string(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object DockerCommandLineCodeExecutor.stop at 0x1200107c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_executor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67086cf860b2\n"
     ]
    }
   ],
   "source": [
    "!docker ps | grep autogen | awk '{print $1}' | xargs -I % docker rm -f %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.http import HttpTool\n",
    "\n",
    "# Define a JSON schema for a base64 decode tool\n",
    "base64_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"value\": {\"type\": \"string\", \"description\": \"The base64 value to decode\"},\n",
    "    },\n",
    "    \"required\": [\"value\"],\n",
    "}\n",
    "\n",
    "# Create an HTTP tool for the httpbin API\n",
    "base64_tool = HttpTool(\n",
    "    name=\"base64_decode\",\n",
    "    description=\"base64 decode a value\",\n",
    "    scheme=\"https\",\n",
    "    host=\"httpbin.org\",\n",
    "    port=443,\n",
    "    path=\"/base64/{value}\",\n",
    "    method=\"GET\",\n",
    "    json_schema=base64_schema,\n",
    ")\n",
    "\n",
    "from models import qwen_25_1_5b\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create an assistant with the base64 tool\n",
    "    # model = OpenAIChatCompletionClient(model=\"gpt-4\")\n",
    "    model = qwen_25_1_5b()\n",
    "    assistant = AssistantAgent(\n",
    "        \"base64_assistant\", model_client=model, tools=[base64_tool]\n",
    "    )\n",
    "\n",
    "    # The assistant can now use the base64 tool to decode the string\n",
    "    response = await assistant.on_messages(\n",
    "        [\n",
    "            TextMessage(\n",
    "                content=\"Can you base64 decode the value 'YWJjZGU=', please?\",\n",
    "                source=\"user\",\n",
    "            )\n",
    "        ],\n",
    "        CancellationToken(),\n",
    "    )\n",
    "    print(response.chat_message.content)\n",
    "\n",
    "\n",
    "# asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.5773285082976\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_core.tools import FunctionTool\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "async def get_stock_price(ticker: str, date: Annotated[str, \"Date in YYYY/MM/DD\"]) -> float:\n",
    "    # Returns a random stock price for demonstration purposes.\n",
    "    return random.uniform(10, 200)\n",
    "\n",
    "\n",
    "# Create a function tool.\n",
    "stock_price_tool = FunctionTool(get_stock_price, description=\"Get the stock price.\")\n",
    "\n",
    "# Run the tool.\n",
    "cancellation_token = CancellationToken()\n",
    "result = await stock_price_tool.run_json({\"ticker\": \"AAPL\", \"date\": \"2021/01/01\"}, cancellation_token)\n",
    "\n",
    "# Print the result.\n",
    "print(stock_price_tool.return_value_as_string(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionCall(id='call_hab2j2e4', arguments='{\"date\":\"2021-01-01\",\"ticker\":\"AAPL\"}', name='get_stock_price')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from autogen_core.models import AssistantMessage, FunctionExecutionResult, FunctionExecutionResultMessage, UserMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Create the OpenAI chat completion client. Using OPENAI_API_KEY from environment variable.\n",
    "# client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "client = qwen_25_1_5b()\n",
    "\n",
    "# Create a user message.\n",
    "user_message = UserMessage(content=\"What is the stock price of AAPL on 2021/01/01?\", source=\"user\")\n",
    "\n",
    "# Run the chat completion with the stock_price_tool defined above.\n",
    "cancellation_token = CancellationToken()\n",
    "create_result = await client.create(\n",
    "    messages=[user_message], tools=[stock_price_tool], cancellation_token=cancellation_token\n",
    ")\n",
    "create_result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'113.2411628885206'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments = json.loads(create_result.content[0].arguments)  # type: ignore\n",
    "tool_result = await stock_price_tool.run_json(arguments, cancellation_token)\n",
    "tool_result_str = stock_price_tool.return_value_as_string(tool_result)\n",
    "tool_result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stock price of AAPL on 2021/01/01 was approximately $113.24.\n"
     ]
    }
   ],
   "source": [
    "# Create a function execution result\n",
    "exec_result = FunctionExecutionResult(\n",
    "    call_id=create_result.content[0].id,  # type: ignore\n",
    "    content=tool_result_str,\n",
    "    is_error=False,\n",
    "    name=stock_price_tool.name,\n",
    ")\n",
    "\n",
    "# Make another chat completion with the history and function execution result message.\n",
    "messages = [\n",
    "    user_message,\n",
    "    AssistantMessage(content=create_result.content, source=\"assistant\"),  # assistant message with tool call\n",
    "    FunctionExecutionResultMessage(content=[exec_result]),  # function execution result message\n",
    "]\n",
    "create_result = await client.create(messages=messages, cancellation_token=cancellation_token)  # type: ignore\n",
    "print(create_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "from autogen_core import (\n",
    "    AgentId,\n",
    "    FunctionCall,\n",
    "    MessageContext,\n",
    "    RoutedAgent,\n",
    "    SingleThreadedAgentRuntime,\n",
    "    message_handler,\n",
    ")\n",
    "from autogen_core.models import (\n",
    "    ChatCompletionClient,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "from autogen_core.tools import FunctionTool, Tool\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "\n",
    "\n",
    "class ToolUseAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient, tool_schema: List[Tool]) -> None:\n",
    "        super().__init__(\"An agent with tools\")\n",
    "        self._system_messages: List[LLMMessage] = [SystemMessage(content=\"You are a helpful AI assistant.\")]\n",
    "        self._model_client = model_client\n",
    "        self._tools = tool_schema\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        # Create a session of messages.\n",
    "        session: List[LLMMessage] = self._system_messages + [UserMessage(content=message.content, source=\"user\")]\n",
    "\n",
    "        # Run the chat completion with the tools.\n",
    "        create_result = await self._model_client.create(\n",
    "            messages=session,\n",
    "            tools=self._tools,\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "\n",
    "        # If there are no tool calls, return the result.\n",
    "        if isinstance(create_result.content, str):\n",
    "            return Message(content=create_result.content)\n",
    "        assert isinstance(create_result.content, list) and all(\n",
    "            isinstance(call, FunctionCall) for call in create_result.content\n",
    "        )\n",
    "\n",
    "        # Add the first model create result to the session.\n",
    "        session.append(AssistantMessage(content=create_result.content, source=\"assistant\"))\n",
    "\n",
    "        # Execute the tool calls.\n",
    "        results = await asyncio.gather(\n",
    "            *[self._execute_tool_call(call, ctx.cancellation_token) for call in create_result.content]\n",
    "        )\n",
    "\n",
    "        # Add the function execution results to the session.\n",
    "        session.append(FunctionExecutionResultMessage(content=results))\n",
    "\n",
    "        # Run the chat completion again to reflect on the history and function execution results.\n",
    "        create_result = await self._model_client.create(\n",
    "            messages=session,\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        assert isinstance(create_result.content, str)\n",
    "\n",
    "        # Return the result as a message.\n",
    "        return Message(content=create_result.content)\n",
    "\n",
    "    async def _execute_tool_call(\n",
    "        self, call: FunctionCall, cancellation_token: CancellationToken\n",
    "    ) -> FunctionExecutionResult:\n",
    "        # Find the tool by name.\n",
    "        tool = next((tool for tool in self._tools if tool.name == call.name), None)\n",
    "        assert tool is not None\n",
    "\n",
    "        # Run the tool and capture the result.\n",
    "        try:\n",
    "            arguments = json.loads(call.arguments)\n",
    "            result = await tool.run_json(arguments, cancellation_token)\n",
    "            return FunctionExecutionResult(\n",
    "                call_id=call.id, content=tool.return_value_as_string(result), is_error=False, name=tool.name\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return FunctionExecutionResult(call_id=call.id, content=str(e), is_error=True, name=tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='tool_use_agent')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a runtime.\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "# Create the tools.\n",
    "tools: List[Tool] = [FunctionTool(get_stock_price, description=\"Get the stock price.\")]\n",
    "# Register the agents.\n",
    "await ToolUseAgent.register(\n",
    "    runtime,\n",
    "    \"tool_use_agent\",\n",
    "    lambda: ToolUseAgent(\n",
    "        # OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "        qwen_25_1_5b(),\n",
    "        tools,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stock price of NVDA on the date June 1, 2024 is approximately $60.59.\n"
     ]
    }
   ],
   "source": [
    "# Start processing messages.\n",
    "runtime.start()\n",
    "# Send a direct message to the tool agent.\n",
    "tool_use_agent = AgentId(\"tool_use_agent\", \"default\")\n",
    "response = await runtime.send_message(Message(\"What is the stock price of NVDA on 2024/06/01?\"), tool_use_agent)\n",
    "print(response.content)\n",
    "# Stop processing messages.\n",
    "await runtime.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_manus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
