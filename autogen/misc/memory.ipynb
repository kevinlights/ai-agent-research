{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../libs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_client = litellm_proxy(\"ollama/qwen2.5:7b\")\n",
    "model_client = litellm_proxy()\n",
    "model_client = qwen2_5_coder_7b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是个由阿里巴巴云开发的人工智能助手，你也可以叫我Qwen。我的全名是通义千问。我是用来与用户交流并尽力帮助他们回答问题、提供信息或是完成各种任务的一个模型。无论你是需要学术上的解答、日常生活小知识，还是想要进行闲聊，我都可以帮助你！如果你有任何问题或需要帮助，请随时告诉我吧。\n"
     ]
    }
   ],
   "source": [
    "resp = await chat(\"你好，请介绍一下你自己\", model_client)\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.memory import ListMemory, MemoryContent, MemoryMimeType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What is the weather in New York?\n",
      "---------- my_assistant ----------\n",
      "[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)]\n",
      "---------- my_assistant ----------\n",
      "[FunctionCall(id='call_o38id6u4', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')]\n",
      "[Prompt tokens: 200, Completion tokens: 30]\n",
      "---------- my_assistant ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_o38id6u4', is_error=False)]\n",
      "---------- my_assistant ----------\n",
      "The weather in New York is 23 °C and Sunny.\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: None\n",
      "Total prompt tokens: 200\n",
      "Total completion tokens: 30\n",
      "Duration: 2.35 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='What is the weather in New York?', type='TextMessage'), MemoryQueryEvent(source='my_assistant', models_usage=None, metadata={}, content=[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)], type='MemoryQueryEvent'), ToolCallRequestEvent(source='my_assistant', models_usage=RequestUsage(prompt_tokens=200, completion_tokens=30), metadata={}, content=[FunctionCall(id='call_o38id6u4', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='my_assistant', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_o38id6u4', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='my_assistant', models_usage=None, metadata={}, content='The weather in New York is 23 °C and Sunny.', type='ToolCallSummaryMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_memory = ListMemory()\n",
    "await user_memory.add(\n",
    "    MemoryContent(\n",
    "        content=\"The weather should be in metric units\",\n",
    "        mime_type=MemoryMimeType.TEXT,\n",
    "    )\n",
    ")\n",
    "await user_memory.add(\n",
    "    MemoryContent(\n",
    "        content=\"Meal recipe must be vegan\",\n",
    "        mime_type=MemoryMimeType.TEXT,\n",
    "    )\n",
    ")\n",
    "async def get_weather(city: str, units: str = \"imperial\") -> str:\n",
    "    if units == \"imperial\":\n",
    "        return f\"The weather in {city} is 73 °F and Sunny.\"\n",
    "    elif units == \"metric\":\n",
    "        return f\"The weather in {city} is 23 °C and Sunny.\"\n",
    "    else:\n",
    "        return f\"Sorry, I don't know the weather in {city}.\"\n",
    "\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"my_assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    memory=[user_memory],\n",
    ")\n",
    "await Console(\n",
    "    assistant_agent.run_stream(\n",
    "        task=\"What is the weather in New York?\",\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserMessage(content='What is the weather in New York?', source='user', type='UserMessage'),\n",
       " SystemMessage(content='\\nRelevant memory content (in chronological order):\\n1. The weather should be in metric units\\n2. Meal recipe must be vegan\\n', type='SystemMessage'),\n",
       " AssistantMessage(content=[FunctionCall(id='call_o38id6u4', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')], thought=None, source='my_assistant', type='AssistantMessage'),\n",
       " FunctionExecutionResultMessage(content=[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_o38id6u4', is_error=False)], type='FunctionExecutionResultMessage')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await assistant_agent._model_context.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write brief meal recipe with broth\n",
      "---------- my_assistant ----------\n",
      "[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)]\n",
      "---------- my_assistant ----------\n",
      "Here's a brief vegan meal recipe using broth:\n",
      "\n",
      "### Vegan Mushroom Soup\n",
      "\n",
      "#### Ingredients:\n",
      "- 4 large mushrooms (shiitake, oyster, porcini), sliced\n",
      "- 1 large onion, chopped\n",
      "- 2 cloves garlic, minced\n",
      "- 3 celery stalks, sliced\n",
      "- 2 carrots, diced\n",
      "- 4 cups vegetable broth\n",
      "- 1/2 teaspoon dried thyme\n",
      "- Salt and pepper to taste\n",
      "- Optional garnish: fresh herbs, nutmeg\n",
      "\n",
      "#### Instructions:\n",
      "1. In a large pot, sauté the onions, garlic, celery, and carrots over medium heat until they are soft and translucent.\n",
      "2. Add the sliced mushrooms and thyme to the pot. Cook for another 5 minutes or until the mushrooms are tender.\n",
      "3. Pour in the vegetable broth, bring the mixture to a simmer, then reduce the heat and let it cook for about 10 minutes until the soup is thick and flavorful.\n",
      "4. Season with salt and pepper to taste.\n",
      "\n",
      "Serve hot, garnished with fresh herbs if desired. Enjoy your delicious vegan mushroom soup in metric units!\n",
      "[Prompt tokens: 293, Completion tokens: 231]\n",
      "---------- Summary ----------\n",
      "Number of messages: 3\n",
      "Finish reason: None\n",
      "Total prompt tokens: 293\n",
      "Total completion tokens: 231\n",
      "Duration: 11.85 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Write brief meal recipe with broth', type='TextMessage'), MemoryQueryEvent(source='my_assistant', models_usage=None, metadata={}, content=[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)], type='MemoryQueryEvent'), TextMessage(source='my_assistant', models_usage=RequestUsage(prompt_tokens=293, completion_tokens=231), metadata={}, content=\"Here's a brief vegan meal recipe using broth:\\n\\n### Vegan Mushroom Soup\\n\\n#### Ingredients:\\n- 4 large mushrooms (shiitake, oyster, porcini), sliced\\n- 1 large onion, chopped\\n- 2 cloves garlic, minced\\n- 3 celery stalks, sliced\\n- 2 carrots, diced\\n- 4 cups vegetable broth\\n- 1/2 teaspoon dried thyme\\n- Salt and pepper to taste\\n- Optional garnish: fresh herbs, nutmeg\\n\\n#### Instructions:\\n1. In a large pot, sauté the onions, garlic, celery, and carrots over medium heat until they are soft and translucent.\\n2. Add the sliced mushrooms and thyme to the pot. Cook for another 5 minutes or until the mushrooms are tender.\\n3. Pour in the vegetable broth, bring the mixture to a simmer, then reduce the heat and let it cook for about 10 minutes until the soup is thick and flavorful.\\n4. Season with salt and pepper to taste.\\n\\nServe hot, garnished with fresh herbs if desired. Enjoy your delicious vegan mushroom soup in metric units!\", type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(\n",
    "    assistant_agent.run_stream(\n",
    "        task=\"Write brief meal recipe with broth\",\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.memory import MemoryContent, MemoryMimeType\n",
    "from autogen_ext.memory.chromadb import ChromaDBVectorMemory, PersistentChromaDBVectorMemoryConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_user_memory = ChromaDBVectorMemory(\n",
    "    config=PersistentChromaDBVectorMemoryConfig(\n",
    "        collection_name=\"preferences\",\n",
    "        persistence_path=os.path.join(os.path.curdir, \".chromadb_autogen\"),\n",
    "        k=2, # return top k results\n",
    "        score_threshold=0.4, # minimum similarity score\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "await chroma_user_memory.add(\n",
    "    MemoryContent(\n",
    "        content=\"The weather should be in metric units\",\n",
    "        mime_type=MemoryMimeType.TEXT,\n",
    "        metadata={\"category\": \"preferences\", \"type\": \"units\"},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "await chroma_user_memory.add(\n",
    "    MemoryContent(\n",
    "        content=\"Meal recipe must be vegan\",\n",
    "        mime_type=MemoryMimeType.TEXT,\n",
    "        metadata={\"category\": \"preferences\", \"type\": \"dietary\"},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What is the weather in New York?\n",
      "---------- new_assistant ----------\n",
      "[MemoryContent(content='The weather should be in metric units', mime_type='MemoryMimeType.TEXT', metadata={'category': 'preferences', 'mime_type': 'MemoryMimeType.TEXT', 'type': 'units', 'score': 0.4342913043162199, 'id': '6e9b8ab9-9783-4008-823c-493a7b0f1b15'})]\n",
      "---------- new_assistant ----------\n",
      "[FunctionCall(id='call_w8n3ec2w', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')]\n",
      "[Prompt tokens: 188, Completion tokens: 31]\n",
      "---------- new_assistant ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_w8n3ec2w', is_error=False)]\n",
      "---------- new_assistant ----------\n",
      "The weather in New York is 23 °C and Sunny.\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: None\n",
      "Total prompt tokens: 188\n",
      "Total completion tokens: 31\n",
      "Duration: 3.47 seconds\n",
      "---------- user ----------\n",
      "Write brief meal recipe with broth\n",
      "---------- new_assistant ----------\n",
      "[MemoryContent(content='Meal recipe must be vegan', mime_type='MemoryMimeType.TEXT', metadata={'category': 'preferences', 'mime_type': 'MemoryMimeType.TEXT', 'type': 'dietary', 'score': 0.522965754519743, 'id': '708d7dd1-f872-4537-b3f7-741f975d69a0'})]\n",
      "---------- new_assistant ----------\n",
      "<recipe>\n",
      "    <title>Vegan Vegetable Broth Soup</title>\n",
      "    <ingredients>\n",
      "        <li>500ml vegetable broth</li>\n",
      "        <li>2 carrots, chopped</li>\n",
      "        <li>1 celery stalk, chopped</li>\n",
      "        <li>3 cloves garlic, minced</li>\n",
      "        <li>1 onion, diced</li>\n",
      "        <li>1 tsp dried thyme</li>\n",
      "        <li>1 bay leaf</li>\n",
      "        <li>Salt and pepper to taste</li>\n",
      "    </ingredients>\n",
      "    <instructions>\n",
      "        <p>Cook the carrots, celery, garlic, and onion in a large pot over medium heat until soft.</p>\n",
      "        <p>Add the thyme, bay leaf, vegetable broth, salt, and pepper. Bring to a boil.</p>\n",
      "        <p>Reduce heat and simmer for 30 minutes or until the vegetables are tender. Discard the bay leaf before serving.</p>\n",
      "    </instructions>\n",
      "</recipe>\n",
      "[Prompt tokens: 267, Completion tokens: 210]\n",
      "---------- Summary ----------\n",
      "Number of messages: 3\n",
      "Finish reason: None\n",
      "Total prompt tokens: 267\n",
      "Total completion tokens: 210\n",
      "Duration: 10.88 seconds\n"
     ]
    }
   ],
   "source": [
    "assistant_agent = AssistantAgent(\n",
    "    name=\"new_assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    memory=[chroma_user_memory],\n",
    ")\n",
    "await Console(\n",
    "    assistant_agent.run_stream(\n",
    "        task=\"What is the weather in New York?\",\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")\n",
    "await Console(\n",
    "    assistant_agent.run_stream(\n",
    "        task=\"Write brief meal recipe with broth\",\n",
    "    ),\n",
    "    output_stats=True,\n",
    ")\n",
    "\n",
    "await chroma_user_memory.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"provider\":\"autogen_ext.memory.chromadb.ChromaDBVectorMemory\",\"component_type\":\"memory\",\"version\":1,\"component_version\":1,\"description\":\"Store and retrieve memory using vector similarity search powered by ChromaDB.\",\"label\":\"ChromaDBVectorMemory\",\"config\":{\"client_type\":\"persistent\",\"collection_name\":\"preferences\",\"distance_metric\":\"cosine\",\"k\":2,\"score_threshold\":0.4,\"allow_reset\":false,\"tenant\":\"default_tenant\",\"database\":\"default_database\",\"persistence_path\":\"./.chromadb_autogen\"}}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_user_memory.dump_component().model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_manus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
