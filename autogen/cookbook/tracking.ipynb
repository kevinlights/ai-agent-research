{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../libs\")\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from autogen_core.logging import LLMCallEvent\n",
    "\n",
    "\n",
    "class LLMUsageTracker(logging.Handler):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Logging handler that tracks the number of tokens used in the prompt and completion.\"\"\"\n",
    "        super().__init__()\n",
    "        self._prompt_tokens = 0\n",
    "        self._completion_tokens = 0\n",
    "\n",
    "    @property\n",
    "    def tokens(self) -> int:\n",
    "        return self._prompt_tokens + self._completion_tokens\n",
    "\n",
    "    @property\n",
    "    def prompt_tokens(self) -> int:\n",
    "        return self._prompt_tokens\n",
    "\n",
    "    @property\n",
    "    def completion_tokens(self) -> int:\n",
    "        return self._completion_tokens\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._prompt_tokens = 0\n",
    "        self._completion_tokens = 0\n",
    "\n",
    "    def emit(self, record: logging.LogRecord) -> None:\n",
    "        \"\"\"Emit the log record. To be used by the logging module.\"\"\"\n",
    "        try:\n",
    "            # Use the StructuredMessage if the message is an instance of it\n",
    "            if isinstance(record.msg, LLMCallEvent):\n",
    "                event = record.msg\n",
    "                self._prompt_tokens += event.prompt_tokens\n",
    "                self._completion_tokens += event.completion_tokens\n",
    "        except Exception:\n",
    "            self.handleError(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有一个老人走入一家餐厅，发现餐厅里有一位穿着 formal 的女士。老人的脑子里突然 flashed 一下感慨：“这位老人可能是我的长辈啊。”但又不想暴露自己的真实身份，所以他说：“你是有名的医生吗？”女士 reply “我不是医生，偶尔做一些研究工作”，老人听了，很是感动。\n",
      "36\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "from autogen_core import EVENT_LOGGER_NAME\n",
    "\n",
    "# Set up the logging configuration to use the custom handler\n",
    "logger = logging.getLogger(EVENT_LOGGER_NAME)\n",
    "logger.setLevel(logging.INFO)\n",
    "llm_usage = LLMUsageTracker()\n",
    "logger.handlers = [llm_usage]\n",
    "\n",
    "# client.create(...)\n",
    "res = await chat(\"你好，请讲个笑话\", litellm_llama32_1b())\n",
    "print(res.content)\n",
    "\n",
    "print(llm_usage.prompt_tokens)\n",
    "print(llm_usage.completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_manus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
