{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.memory import ListMemory, MemoryContent, MemoryMimeType\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize user memory\n",
    "user_memory = ListMemory()\n",
    "\n",
    "# Add user preferences to memory\n",
    "await user_memory.add(MemoryContent(content=\"The weather should be in metric units\", mime_type=MemoryMimeType.TEXT))\n",
    "\n",
    "await user_memory.add(MemoryContent(content=\"Meal recipe must be vegan\", mime_type=MemoryMimeType.TEXT))\n",
    "\n",
    "\n",
    "async def get_weather(city: str, units: str = \"imperial\") -> str:\n",
    "    if units == \"imperial\":\n",
    "        return f\"The weather in {city} is 73 °F and Sunny.\"\n",
    "    elif units == \"metric\":\n",
    "        return f\"The weather in {city} is 23 °C and Sunny.\"\n",
    "    else:\n",
    "        return f\"Sorry, I don't know the weather in {city}.\"\n",
    "\n",
    "from autogen_core.models import ModelFamily\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"qwen2.5-coder:7b\",\n",
    "    # model=\"mistral-nemo:12b\",\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"placeholder\",\n",
    "    model_info={\n",
    "        \"vision\": False,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": True,\n",
    "        \"family\": ModelFamily.ANY,\n",
    "    },\n",
    ")\n",
    "\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    memory=[user_memory],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What is the weather in New York?\n",
      "---------- assistant_agent ----------\n",
      "[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)]\n",
      "---------- assistant_agent ----------\n",
      "[FunctionCall(id='call_n18j6t9c', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')]\n",
      "[Prompt tokens: 200, Completion tokens: 31]\n",
      "---------- assistant_agent ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_n18j6t9c', is_error=False)]\n",
      "---------- assistant_agent ----------\n",
      "The weather in New York is 23 °C and Sunny.\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: None\n",
      "Total prompt tokens: 200\n",
      "Total completion tokens: 31\n",
      "Duration: 2.57 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='What is the weather in New York?', type='TextMessage'), MemoryQueryEvent(source='assistant_agent', models_usage=None, metadata={}, content=[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)], type='MemoryQueryEvent'), ToolCallRequestEvent(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=200, completion_tokens=31), metadata={}, content=[FunctionCall(id='call_n18j6t9c', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant_agent', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_n18j6t9c', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='assistant_agent', models_usage=None, metadata={}, content='The weather in New York is 23 °C and Sunny.', type='ToolCallSummaryMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the agent with a task.\n",
    "stream = assistant_agent.run_stream(task=\"What is the weather in New York?\")\n",
    "await Console(stream, output_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserMessage(content='What is the weather in New York?', source='user', type='UserMessage'),\n",
       " SystemMessage(content='\\nRelevant memory content (in chronological order):\\n1. The weather should be in metric units\\n2. Meal recipe must be vegan\\n', type='SystemMessage'),\n",
       " AssistantMessage(content=[FunctionCall(id='call_n18j6t9c', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')], thought=None, source='assistant_agent', type='AssistantMessage'),\n",
       " FunctionExecutionResultMessage(content=[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_n18j6t9c', is_error=False)], type='FunctionExecutionResultMessage')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await assistant_agent._model_context.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write brief meal recipe with broth\n",
      "---------- assistant_agent ----------\n",
      "[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)]\n",
      "---------- assistant_agent ----------\n",
      "Here's a simple vegan meal recipe using broth:\n",
      "\n",
      "### Vegan Broccoli Soup\n",
      "\n",
      "#### Ingredients:\n",
      "- 2 cups frozen broccoli florets\n",
      "- 1 onion, finely chopped\n",
      "- 2 cloves garlic, minced\n",
      "- 4 cups vegetable broth (low-sodium if possible)\n",
      "- ½ teaspoon salt\n",
      "- ¼ teaspoon black pepper\n",
      "- A dash of fresh parsley for garnish (optional)\n",
      "\n",
      "#### Instructions:\n",
      "1. In a large pot, heat the broth over low Heat.\n",
      "2. Add the onion and garlic and cook until soft and fragrant, about 5 minutes.\n",
      "3. Add the frozen broccoli and cook for another 5-7 minutes or until tender.\n",
      "4. Season with salt and black pepper to taste.\n",
      "5. If needed, add a splash more broth to achieve desired consistency.\n",
      "6. Garnish with fresh parsley if using.\n",
      "\n",
      "Enjoy your vegan broccoli soup!\n",
      "[Prompt tokens: 293, Completion tokens: 181]\n",
      "---------- Summary ----------\n",
      "Number of messages: 3\n",
      "Finish reason: None\n",
      "Total prompt tokens: 293\n",
      "Total completion tokens: 181\n",
      "Duration: 9.83 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Write brief meal recipe with broth', type='TextMessage'), MemoryQueryEvent(source='assistant_agent', models_usage=None, metadata={}, content=[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)], type='MemoryQueryEvent'), TextMessage(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=293, completion_tokens=181), metadata={}, content=\"Here's a simple vegan meal recipe using broth:\\n\\n### Vegan Broccoli Soup\\n\\n#### Ingredients:\\n- 2 cups frozen broccoli florets\\n- 1 onion, finely chopped\\n- 2 cloves garlic, minced\\n- 4 cups vegetable broth (low-sodium if possible)\\n- ½ teaspoon salt\\n- ¼ teaspoon black pepper\\n- A dash of fresh parsley for garnish (optional)\\n\\n#### Instructions:\\n1. In a large pot, heat the broth over low Heat.\\n2. Add the onion and garlic and cook until soft and fragrant, about 5 minutes.\\n3. Add the frozen broccoli and cook for another 5-7 minutes or until tender.\\n4. Season with salt and black pepper to taste.\\n5. If needed, add a splash more broth to achieve desired consistency.\\n6. Garnish with fresh parsley if using.\\n\\nEnjoy your vegan broccoli soup!\", type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = assistant_agent.run_stream(task=\"Write brief meal recipe with broth\")\n",
    "await Console(stream, output_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "请用中文翻译以上回复\n",
      "---------- assistant_agent ----------\n",
      "[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)]\n",
      "---------- assistant_agent ----------\n",
      "以下是使用汤的基本的素食餐食配方：\n",
      "\n",
      "### 蔬菜汤\n",
      "\n",
      "#### 配料：\n",
      "- 2杯冻西兰花\n",
      "- 一个切成细丝的大葱\n",
      "- 两瓣大蒜，剁碎\n",
      "- 4杯蔬菜汤（尽量选择低钠的）\n",
      "- 半茶匙食盐\n",
      "- 四分之一茶匙黑胡椒\n",
      "- 一些新鲜的欧芹作为装饰（可选）\n",
      "\n",
      "#### 做法：\n",
      "1. 在一个大锅中，用小火加热鸡汤。\n",
      "2. 加入大葱和大蒜并煮至软且香，约5分钟。\n",
      "3. 添加冻西兰花并煮5到7分钟或直到变熟。\n",
      "4. 根据口味添加食盐和黑胡椒调味。\n",
      "5. 如果需要，可加入一些汤以达到所需的质地。\n",
      "6. 用新鲜的欧芹装饰，如果使用的话。\n",
      "\n",
      "现在即可享用你的素食西兰花汤！\n",
      "[Prompt tokens: 516, Completion tokens: 202]\n",
      "---------- Summary ----------\n",
      "Number of messages: 3\n",
      "Finish reason: None\n",
      "Total prompt tokens: 516\n",
      "Total completion tokens: 202\n",
      "Duration: 11.86 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='请用中文翻译以上回复', type='TextMessage'), MemoryQueryEvent(source='assistant_agent', models_usage=None, metadata={}, content=[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)], type='MemoryQueryEvent'), TextMessage(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=516, completion_tokens=202), metadata={}, content='以下是使用汤的基本的素食餐食配方：\\n\\n### 蔬菜汤\\n\\n#### 配料：\\n- 2杯冻西兰花\\n- 一个切成细丝的大葱\\n- 两瓣大蒜，剁碎\\n- 4杯蔬菜汤（尽量选择低钠的）\\n- 半茶匙食盐\\n- 四分之一茶匙黑胡椒\\n- 一些新鲜的欧芹作为装饰（可选）\\n\\n#### 做法：\\n1. 在一个大锅中，用小火加热鸡汤。\\n2. 加入大葱和大蒜并煮至软且香，约5分钟。\\n3. 添加冻西兰花并煮5到7分钟或直到变熟。\\n4. 根据口味添加食盐和黑胡椒调味。\\n5. 如果需要，可加入一些汤以达到所需的质地。\\n6. 用新鲜的欧芹装饰，如果使用的话。\\n\\n现在即可享用你的素食西兰花汤！', type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = assistant_agent.run_stream(task=\"请用中文翻译以上回复\")\n",
    "await Console(stream, output_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinlights/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:13<00:00, 6.06MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What is the weather in New York?\n",
      "---------- assistant_agent ----------\n",
      "[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe must be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)]\n",
      "---------- assistant_agent ----------\n",
      "[FunctionCall(id='call_ddy93dos', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')]\n",
      "[Prompt tokens: 200, Completion tokens: 31]\n",
      "---------- assistant_agent ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_ddy93dos', is_error=False)]\n",
      "---------- assistant_agent ----------\n",
      "The weather in New York is 23 °C and Sunny.\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: None\n",
      "Total prompt tokens: 200\n",
      "Total completion tokens: 31\n",
      "Duration: 2.26 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.memory import MemoryContent, MemoryMimeType\n",
    "from autogen_ext.memory.chromadb import ChromaDBVectorMemory, PersistentChromaDBVectorMemoryConfig\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Initialize ChromaDB memory with custom config\n",
    "chroma_user_memory = ChromaDBVectorMemory(\n",
    "    config=PersistentChromaDBVectorMemoryConfig(\n",
    "        collection_name=\"preferences\",\n",
    "        persistence_path=os.path.join(str(Path.home()), \".chromadb_autogen\"),\n",
    "        k=2,  # Return top  k results\n",
    "        score_threshold=0.4,  # Minimum similarity score\n",
    "    )\n",
    ")\n",
    "# a HttpChromaDBVectorMemoryConfig is also supported for connecting to a remote ChromaDB server\n",
    "\n",
    "# Add user preferences to memory\n",
    "await chroma_user_memory.add(\n",
    "    MemoryContent(\n",
    "        content=\"The weather should be in metric units\",\n",
    "        mime_type=MemoryMimeType.TEXT,\n",
    "        metadata={\"category\": \"preferences\", \"type\": \"units\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "await chroma_user_memory.add(\n",
    "    MemoryContent(\n",
    "        content=\"Meal recipe must be vegan\",\n",
    "        mime_type=MemoryMimeType.TEXT,\n",
    "        metadata={\"category\": \"preferences\", \"type\": \"dietary\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Create assistant agent with ChromaDB memory\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    memory=[user_memory],\n",
    ")\n",
    "\n",
    "stream = assistant_agent.run_stream(task=\"What is the weather in New York?\")\n",
    "await Console(stream, output_stats=True)\n",
    "\n",
    "await user_memory.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"provider\":\"autogen_ext.memory.chromadb.ChromaDBVectorMemory\",\"component_type\":\"memory\",\"version\":1,\"component_version\":1,\"description\":\"Store and retrieve memory using vector similarity search powered by ChromaDB.\",\"label\":\"ChromaDBVectorMemory\",\"config\":{\"client_type\":\"persistent\",\"collection_name\":\"preferences\",\"distance_metric\":\"cosine\",\"k\":2,\"score_threshold\":0.4,\"allow_reset\":false,\"tenant\":\"default_tenant\",\"database\":\"default_database\",\"persistence_path\":\"/Users/kevinlights/.chromadb_autogen\"}}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_user_memory.dump_component().model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_manus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
